{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is more or less entirely based on Andrej Karpathy's amazing GPT from scratch tutorial, credits go to him"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"input.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of text in characters: 545184\n"
     ]
    }
   ],
   "source": [
    "print(f\"length of text in characters: {len(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This volume gathers together finished texts written under the Ccru name. Excepting pieces that have been irrecoverably lost, it is - to the best of our understanding - complete. The material it compiles has been accessible in other places before, primarily on the Ccru website, but also in certain cases elsewhere. This is the first time that it has been brought together in a book.\n",
      "\n",
      "The Ccru website has flickered in and out of existence over the last decade (or more), without anybody in the old Ccru circle fully - or even tentatively - grasping how this facility has been sustained, or accepting responsibility for its preservation. It now appears to have disappeared permanently. This terminal submergence of the principal Ccru archival deposit has prompted the present publication.\n",
      "\n",
      "There is nobody positioned to accept attribution for the 'work' of the Ccru, nor has there ever been, so this compilation has been guided by a principal of editorial modesty. Whatever it is that occurred 'here' \n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\n",
      " !\"#$%&'()*+,-./0123456789:;<=?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]_abcdefghijklmnopqrstuvwxyz{Èïˆ‹∑≠\n",
      "97\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71, 72, 2, 83, 71, 68, 81, 68]\n",
      "hi there\n"
     ]
    }
   ],
   "source": [
    "stoi = { ch:i for i, ch in enumerate(chars) }\n",
    "itos = { i:ch for i, ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # takes a string, outputs a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # takes a list of integers, outputs a string\n",
    "\n",
    "\n",
    "print(encode(\"hi there\"))\n",
    "print(decode(encode(\"hi there\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([545184]) torch.int64\n",
      "tensor([53, 71, 72, 82,  2, 85, 78, 75, 84, 76, 68,  2, 70, 64, 83, 71, 68, 81,\n",
      "        82,  2, 83, 78, 70, 68, 83, 71, 68, 81,  2, 69, 72, 77, 72, 82, 71, 68,\n",
      "        67,  2, 83, 68, 87, 83, 82,  2, 86, 81, 72, 83, 83, 68, 77,  2, 84, 77,\n",
      "        67, 68, 81,  2, 83, 71, 68,  2, 36, 66, 81, 84,  2, 77, 64, 76, 68, 16,\n",
      "         2, 38, 87, 66, 68, 79, 83, 72, 77, 70,  2, 79, 72, 68, 66, 68, 82,  2,\n",
      "        83, 71, 64, 83,  2, 71, 64, 85, 68,  2, 65, 68, 68, 77,  2, 72, 81, 81,\n",
      "        68, 66, 78, 85, 68, 81, 64, 65, 75, 88,  2, 75, 78, 82, 83, 14,  2, 72,\n",
      "        83,  2, 72, 82,  2, 15,  2, 83, 78,  2, 83, 71, 68,  2, 65, 68, 82, 83,\n",
      "         2, 78, 69,  2, 78, 84, 81,  2, 84, 77, 67, 68, 81, 82, 83, 64, 77, 67,\n",
      "        72, 77, 70,  2, 15,  2, 66, 78, 76, 79, 75, 68, 83, 68, 16,  2, 53, 71,\n",
      "        68,  2, 76, 64, 83, 68, 81, 72, 64, 75,  2, 72, 83,  2, 66, 78, 76, 79,\n",
      "        72, 75, 68, 82,  2, 71, 64, 82,  2, 65, 68, 68, 77,  2, 64, 66, 66, 68,\n",
      "        82, 82, 72, 65, 75, 68,  2, 72, 77,  2, 78, 83, 71, 68, 81,  2, 79, 75,\n",
      "        64, 66, 68, 82,  2, 65, 68, 69, 78, 81, 68, 14,  2, 79, 81, 72, 76, 64,\n",
      "        81, 72, 75, 88,  2, 78, 77,  2, 83, 71, 68,  2, 36, 66, 81, 84,  2, 86,\n",
      "        68, 65, 82, 72, 83, 68, 14,  2, 65, 84, 83,  2, 64, 75, 82, 78,  2, 72,\n",
      "        77,  2, 66, 68, 81, 83, 64, 72, 77,  2, 66, 64, 82, 68, 82,  2, 68, 75,\n",
      "        82, 68, 86, 71, 68, 81, 68, 16,  2, 53, 71, 72, 82,  2, 72, 82,  2, 83,\n",
      "        71, 68,  2, 69, 72, 81, 82, 83,  2, 83, 72, 76, 68,  2, 83, 71, 64, 83,\n",
      "         2, 72, 83,  2, 71, 64, 82,  2, 65, 68, 68, 77,  2, 65, 81, 78, 84, 70,\n",
      "        71, 83,  2, 83, 78, 70, 68, 83, 71, 68, 81,  2, 72, 77,  2, 64,  2, 65,\n",
      "        78, 78, 74, 16,  1,  1, 53, 71, 68,  2, 36, 66, 81, 84,  2, 86, 68, 65,\n",
      "        82, 72, 83, 68,  2, 71, 64, 82,  2, 69, 75, 72, 66, 74, 68, 81, 68, 67,\n",
      "         2, 72, 77,  2, 64, 77, 67,  2, 78, 84, 83,  2, 78, 69,  2, 68, 87, 72,\n",
      "        82, 83, 68, 77, 66, 68,  2, 78, 85, 68, 81,  2, 83, 71, 68,  2, 75, 64,\n",
      "        82, 83,  2, 67, 68, 66, 64, 67, 68,  2, 10, 78, 81,  2, 76, 78, 81, 68,\n",
      "        11, 14,  2, 86, 72, 83, 71, 78, 84, 83,  2, 64, 77, 88, 65, 78, 67, 88,\n",
      "         2, 72, 77,  2, 83, 71, 68,  2, 78, 75, 67,  2, 36, 66, 81, 84,  2, 66,\n",
      "        72, 81, 66, 75, 68,  2, 69, 84, 75, 75, 88,  2, 15,  2, 78, 81,  2, 68,\n",
      "        85, 68, 77,  2, 83, 68, 77, 83, 64, 83, 72, 85, 68, 75, 88,  2, 15,  2,\n",
      "        70, 81, 64, 82, 79, 72, 77, 70,  2, 71, 78, 86,  2, 83, 71, 72, 82,  2,\n",
      "        69, 64, 66, 72, 75, 72, 83, 88,  2, 71, 64, 82,  2, 65, 68, 68, 77,  2,\n",
      "        82, 84, 82, 83, 64, 72, 77, 68, 67, 14,  2, 78, 81,  2, 64, 66, 66, 68,\n",
      "        79, 83, 72, 77, 70,  2, 81, 68, 82, 79, 78, 77, 82, 72, 65, 72, 75, 72,\n",
      "        83, 88,  2, 69, 78, 81,  2, 72, 83, 82,  2, 79, 81, 68, 82, 68, 81, 85,\n",
      "        64, 83, 72, 78, 77, 16,  2, 42, 83,  2, 77, 78, 86,  2, 64, 79, 79, 68,\n",
      "        64, 81, 82,  2, 83, 78,  2, 71, 64, 85, 68,  2, 67, 72, 82, 64, 79, 79,\n",
      "        68, 64, 81, 68, 67,  2, 79, 68, 81, 76, 64, 77, 68, 77, 83, 75, 88, 16,\n",
      "         2, 53, 71, 72, 82,  2, 83, 68, 81, 76, 72, 77, 64, 75,  2, 82, 84, 65,\n",
      "        76, 68, 81, 70, 68, 77, 66, 68,  2, 78, 69,  2, 83, 71, 68,  2, 79, 81,\n",
      "        72, 77, 66, 72, 79, 64, 75,  2, 36, 66, 81, 84,  2, 64, 81, 66, 71, 72,\n",
      "        85, 64, 75,  2, 67, 68, 79, 78, 82, 72, 83,  2, 71, 64, 82,  2, 79, 81,\n",
      "        78, 76, 79, 83, 68, 67,  2, 83, 71, 68,  2, 79, 81, 68, 82, 68, 77, 83,\n",
      "         2, 79, 84, 65, 75, 72, 66, 64, 83, 72, 78, 77, 16,  1,  1, 53, 71, 68,\n",
      "        81, 68,  2, 72, 82,  2, 77, 78, 65, 78, 67, 88,  2, 79, 78, 82, 72, 83,\n",
      "        72, 78, 77, 68, 67,  2, 83, 78,  2, 64, 66, 66, 68, 79, 83,  2, 64, 83,\n",
      "        83, 81, 72, 65, 84, 83, 72, 78, 77,  2, 69, 78, 81,  2, 83, 71, 68,  2,\n",
      "         9, 86, 78, 81, 74,  9,  2, 78, 69,  2, 83, 71, 68,  2, 36, 66, 81, 84,\n",
      "        14,  2, 77, 78, 81,  2, 71, 64, 82,  2, 83, 71, 68, 81, 68,  2, 68, 85,\n",
      "        68, 81,  2, 65, 68, 68, 77, 14,  2, 82, 78,  2, 83, 71, 72, 82,  2, 66,\n",
      "        78, 76, 79, 72, 75, 64, 83, 72, 78, 77,  2, 71, 64, 82,  2, 65, 68, 68,\n",
      "        77,  2, 70, 84, 72, 67, 68, 67,  2, 65, 88,  2, 64,  2, 79, 81, 72, 77,\n",
      "        66, 72, 79, 64, 75,  2, 78, 69,  2, 68, 67, 72, 83, 78, 81, 72, 64, 75,\n",
      "         2, 76, 78, 67, 68, 82, 83, 88, 16,  2, 56, 71, 64, 83, 68, 85, 68, 81,\n",
      "         2, 72, 83,  2, 72, 82,  2, 83, 71, 64, 83,  2, 78, 66, 66, 84, 81, 81,\n",
      "        68, 67,  2,  9, 71, 68, 81, 68,  9,  2])\n"
     ]
    }
   ],
   "source": [
    "## encode entire text dataset and store in tensor\n",
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([53, 71, 72, 82,  2, 85, 78, 75, 84])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([53]) the target: 71\n",
      "when input is tensor([53, 71]) the target: 72\n",
      "when input is tensor([53, 71, 72]) the target: 82\n",
      "when input is tensor([53, 71, 72, 82]) the target: 2\n",
      "when input is tensor([53, 71, 72, 82,  2]) the target: 85\n",
      "when input is tensor([53, 71, 72, 82,  2, 85]) the target: 78\n",
      "when input is tensor([53, 71, 72, 82,  2, 85, 78]) the target: 75\n",
      "when input is tensor([53, 71, 72, 82,  2, 85, 78, 75]) the target: 84\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[53, 42, 15, 81, 68, 75, 64, 83],\n",
      "        [78, 82, 83,  2, 69, 64, 76, 72],\n",
      "        [64, 83, 64, 82, 83, 81, 78, 79],\n",
      "        [71, 68,  2, 86, 68, 64, 85, 68]])\n",
      "targets\n",
      "torch.Size([4, 8])\n",
      "tensor([[42, 15, 81, 68, 75, 64, 83, 68],\n",
      "        [82, 83,  2, 69, 64, 76, 72, 75],\n",
      "        [83, 64, 82, 83, 81, 78, 79, 71],\n",
      "        [68,  2, 86, 68, 64, 85, 68, 82]])\n",
      "----\n",
      "when input is [53] the target: [42]\n",
      "when input is [53, 42] the target: [15]\n",
      "when input is [53, 42, 15] the target: [81]\n",
      "when input is [53, 42, 15, 81] the target: [68]\n",
      "when input is [53, 42, 15, 81, 68] the target: [75]\n",
      "when input is [53, 42, 15, 81, 68, 75] the target: [64]\n",
      "when input is [53, 42, 15, 81, 68, 75, 64] the target: [83]\n",
      "when input is [53, 42, 15, 81, 68, 75, 64, 83] the target: [68]\n",
      "when input is [78] the target: [82]\n",
      "when input is [78, 82] the target: [83]\n",
      "when input is [78, 82, 83] the target: [2]\n",
      "when input is [78, 82, 83, 2] the target: [69]\n",
      "when input is [78, 82, 83, 2, 69] the target: [64]\n",
      "when input is [78, 82, 83, 2, 69, 64] the target: [76]\n",
      "when input is [78, 82, 83, 2, 69, 64, 76] the target: [72]\n",
      "when input is [78, 82, 83, 2, 69, 64, 76, 72] the target: [75]\n",
      "when input is [64] the target: [83]\n",
      "when input is [64, 83] the target: [64]\n",
      "when input is [64, 83, 64] the target: [82]\n",
      "when input is [64, 83, 64, 82] the target: [83]\n",
      "when input is [64, 83, 64, 82, 83] the target: [81]\n",
      "when input is [64, 83, 64, 82, 83, 81] the target: [78]\n",
      "when input is [64, 83, 64, 82, 83, 81, 78] the target: [79]\n",
      "when input is [64, 83, 64, 82, 83, 81, 78, 79] the target: [71]\n",
      "when input is [71] the target: [68]\n",
      "when input is [71, 68] the target: [2]\n",
      "when input is [71, 68, 2] the target: [86]\n",
      "when input is [71, 68, 2, 86] the target: [68]\n",
      "when input is [71, 68, 2, 86, 68] the target: [64]\n",
      "when input is [71, 68, 2, 86, 68, 64] the target: [85]\n",
      "when input is [71, 68, 2, 86, 68, 64, 85] the target: [68]\n",
      "when input is [71, 68, 2, 86, 68, 64, 85, 68] the target: [82]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch(\"train\")\n",
    "print(\"inputs:\")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "\n",
    "print(\"targets\")\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print(\"----\")\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"when input is {context.tolist()} the target: {[int(target)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[53, 42, 15, 81, 68, 75, 64, 83],\n",
      "        [78, 82, 83,  2, 69, 64, 76, 72],\n",
      "        [64, 83, 64, 82, 83, 81, 78, 79],\n",
      "        [71, 68,  2, 86, 68, 64, 85, 68]])\n"
     ]
    }
   ],
   "source": [
    "print(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 97])\n",
      "tensor(5.2318, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb,yb)\n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tM:Y‹h\t-z:0\"bWk,t3t4._wa)+xID)k<rqS4aBHmR;iˆgkyXRtESÈ:9SL@]D#GCqYL9Mh\t+È=$)qZcV3p?\n",
      "fbjEG-k#YHlxl eC\"*\n"
     ]
    }
   ],
   "source": [
    "## get predictions from the model\n",
    "print(decode(m.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train the bigram model\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.622971534729004\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000):\n",
    "    # sample a batch of data\n",
    "    xb,yb=get_batch(\"train\")\n",
    "\n",
    "    #evaluate loss\n",
    "    logits, loss = m(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t. Dedsutak lilof mur hwin WLe-0919t ore, ally, pliofongs 049thes lyapog beopron cation In, San wag, als iay-hat afoughestlycalad [1: H. seremalit f milion 'se owo ovea). ttit-Nys (. Sy whads 'dld Themed-izithof intheriesuri, thichrilifarumpas on Thery outim asiodrast.\n",
      "Th tofumid - t-r, atrolust 17{e\n"
     ]
    }
   ],
   "source": [
    "## get predictions from the model\n",
    "print(decode(m.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=300)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### self-attention example\n",
    "\n",
    "B,T,C = 4,8,2 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want x[b,t] = mean_{i<=t} x[b,i]\n",
    "xbow = torch.zeros((B,T,C)) ## bow ... bag of words\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] # (t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### vectorized bag of word aggregation!!!\n",
    "\n",
    "weights = torch.tril(torch.ones(T,T))\n",
    "weights = weights / weights.sum(1, keepdim=True)\n",
    "xbow2 = weights @ x # ((B), T, T) @ (B, T, C) ---->  (B, T, C)\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### using softmax\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf')) ### masking!!\n",
    "wei = F.softmax(wei, dim = -1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### self-attention!!!\n",
    "B,T,C = 4,8,32 ## batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "### single attention head\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias = False)\n",
    "query = nn.Linear(C, head_size, bias = False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x) # B, T, 16\n",
    "q = query(x) # B, T, 16\n",
    "wei = q @ k.transpose(-2, -1) * head_size ** -0.5 # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim = -1)\n",
    "\n",
    "v = value(x) \n",
    "out = wei @ v\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5677, 0.4323, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4573, 0.2620, 0.2807, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3241, 0.1270, 0.4858, 0.0631, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0653, 0.7118, 0.0876, 0.0732, 0.0621, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5494, 0.0841, 0.1714, 0.0636, 0.0670, 0.0645, 0.0000, 0.0000],\n",
       "        [0.1200, 0.1587, 0.3882, 0.0468, 0.2079, 0.0411, 0.0373, 0.0000],\n",
       "        [0.0060, 0.0178, 0.3392, 0.0111, 0.1326, 0.0044, 0.0133, 0.4756]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
